{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/schwartz-cnl/Computational-Neuroscience-Class/blob/main/Convolutional%20Neural%20Network/Experiment_Visualize_pretrained_model.ipynb)"
      ],
      "metadata": {
        "id": "pljYsyAVhFkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook shows you how to load a pretrained keras model, and how to get intermediate layer activations. This is useful in the context of interpreting intermediate deep neural network representations, and for running simulations to compare deep neural network representations to biological visual cortex experiments. The notebook then shows an example of in-silico neurophysiology experiments of probing an artificial neuron with Gabor-like stimuli, and a simple version of visualizing a neuron feature properties.\n",
        "\n",
        "Code by Xu Pan and Odelia Schwartz, with some code adapted from: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011486 The paper code: https://gin.g-node.org/xupan/CNN_surround_effects_visualization"
      ],
      "metadata": {
        "id": "c2G4RJLOazNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/schwartz-cnl/Computational-Neuroscience-Class/blob/main/Convolutional%20Neural%20Network/ILSVRC2012_test_00026783.JPEG?raw=true -O ILSVRC2012_test_00026783.JPEG"
      ],
      "metadata": {
        "id": "ENXtw7YJbqC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# download the pretrained VGG16 model\n",
        "model = VGG16(weights='imagenet', include_top=True)"
      ],
      "metadata": {
        "id": "h2Wh76jlcAUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "ge147IrLcJeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test an image. Note the rest of this tutorial will use grating images\n",
        "# load image\n",
        "img_path = 'ILSVRC2012_test_00026783.JPEG'\n",
        "# preprocess. We use the Keras preprocess_input function.\n",
        "# We alway need to preprocess the input in the same way that the training prepreocessed the input.\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "# predict one-hot label\n",
        "y = model.predict(x)"
      ],
      "metadata": {
        "id": "4a2UzTvNcMGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get intermediate layer activation"
      ],
      "metadata": {
        "id": "ykQ7R_IPcQvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can access an intermediate network layer. You could see the structure of VGG layers in\n",
        "# the model.summary above\n",
        "partial_model = keras.Model(inputs=model.input, outputs=model.get_layer('block3_conv3').output)"
      ],
      "metadata": {
        "id": "WNnodAV1cNSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = partial_model.predict(x)"
      ],
      "metadata": {
        "id": "7XZlDdtBcq0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.shape\n",
        "# For example, for block3_conv3, this gives us a 56x56 spatial map for each of 256 neurons"
      ],
      "metadata": {
        "id": "JA3vZSRvcsUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-silico electrophysiology\n",
        "Let's try to explore some basic properties of the artificial neurons. A good starting point is to find the orientation and spatial period tuning curves.\n",
        "This is commonly done, for instance, in neurophysiology experiments of\n",
        "Primary Visual Cortex (V1) neurons."
      ],
      "metadata": {
        "id": "1DZl5ff_cwRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title A util function to generate stimuli (run this cell)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "def makeGaussian(size, fwhm = 100, center=None):\n",
        "    \"\"\"\n",
        "    Adapt from Andrew Aiessel.\n",
        "    Make a square gaussian kernel.\n",
        "    size is the length of a side of the square\n",
        "    fwhm is full-width-half-maximum, which\n",
        "    can be thought of as an effective radius.\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.arange(0, size, 1, float)\n",
        "    y = x[:,np.newaxis]\n",
        "\n",
        "    if center is None:\n",
        "        x0 = y0 = size // 2\n",
        "    else:\n",
        "        x0 = center[0]\n",
        "        y0 = center[1]\n",
        "\n",
        "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n",
        "\n",
        "def makeGrating(size, spatialp, ori=0, phase=0, imsize=224, dtype='uint8'):\n",
        "    \"\"\"\n",
        "    Make a square grating.\n",
        "    size: the full-width-half-maximum of gaussian mask\n",
        "    which can be thought of as an effective radius.\n",
        "    spatialf: spatial frequency.\n",
        "    ori: orientation, 0 is horizental. 90 is vertical.\n",
        "    phase: 0-360\n",
        "    imsize: the image size.\n",
        "    \"\"\"\n",
        "    im = np.ones(imsize)\n",
        "    # the last term is to make center phase 0.\n",
        "    im = im*[np.sin(2*np.pi/spatialp*x+(phase/np.pi*180-2*np.pi/spatialp*imsize/2)) for x in range(imsize)]\n",
        "    im = np.repeat(im[:,np.newaxis],imsize,axis=1)\n",
        "\n",
        "    gaussianmask = makeGaussian(imsize, size)\n",
        "    im = im*gaussianmask\n",
        "\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.rotate(ori)\n",
        "\n",
        "    im = (np.array(im)+1) / 2 * 255\n",
        "    im = np.repeat(im[:,:,np.newaxis],3,axis=2)\n",
        "    im = im.astype(dtype)\n",
        "    return im"
      ],
      "metadata": {
        "id": "GHNuC9cGcvEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let see some examples of stimuli\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sti1 = makeGrating(size=50, spatialp=20, ori=0, phase=0, imsize=224)\n",
        "plt.figure()\n",
        "plt.imshow(sti1)\n",
        "\n",
        "sti1 = makeGrating(size=50, spatialp=50, ori=45, phase=0, imsize=224)\n",
        "plt.figure()\n",
        "plt.imshow(sti1)\n",
        "\n",
        "sti1 = makeGrating(size=50, spatialp=5, ori=90, phase=0, imsize=224)\n",
        "plt.figure()\n",
        "plt.imshow(sti1)"
      ],
      "metadata": {
        "id": "r8K6bzV-c9U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We will do some simple in-silico neurophysiology on example model neurons. First, we run a tuning heatmap for a neuron"
      ],
      "metadata": {
        "id": "1LlFAkiVdJyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tuningHeatmap(oris, periods, partial_model, spatial_x, spatial_y, neuron):\n",
        "  responses = np.zeros((len(oris), len(periods)))\n",
        "  for i, ori in enumerate(oris):\n",
        "      for j, period in enumerate(periods):\n",
        "          phase_responses = [];\n",
        "          for phase in range(0, 316, 45):  # average over responses to different phases, echoing biology experiments\n",
        "               # Construct the stimulus with phase variation\n",
        "               # Here we set the grating size to 40 to match the block 3, conv 3 theoretical RF size\n",
        "               # Note website  about RF arithmetic:\n",
        "               # https://blog.mlreview.com/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807\n",
        "               sti = makeGrating(size=40, spatialp=period, ori=ori, phase=phase, imsize=224)\n",
        "               sti = np.expand_dims(sti, axis=0)\n",
        "               # The stimuli need to be processed in the same way model was trained!\n",
        "               sti = preprocess_input(sti)\n",
        "               # run the model\n",
        "               prediction = partial_model.predict(sti, verbose=0)\n",
        "               responses_onephase = prediction[0, spatial_x // 2, spatial_y // 2, neuron] # center of the feature map\n",
        "               phase_responses.append(responses_onephase)\n",
        "          # Average responses across different phases\n",
        "          responses[i, j] = np.mean(phase_responses)\n",
        "\n",
        "  # Find the indices of the maximum response\n",
        "  max_index = np.argmax(responses)\n",
        "  maxori, maxperiod = np.unravel_index(max_index, responses.shape)\n",
        "  # plot the tuning heatmap\n",
        "  plt.pcolor(oris, periods, responses.T)\n",
        "  plt.colorbar()\n",
        "  plt.xlabel(\"orientation\")\n",
        "  plt.ylabel(\"spatial period\")\n",
        "  # Return the indices corresponding to the maximum ori and freq\n",
        "  return maxori, maxperiod, responses"
      ],
      "metadata": {
        "id": "_NQyvr34dDfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the TuningHeatmap function, plot the heatmap and find the maximal orientation\n",
        "# and spatial frequency indices\n",
        "partial_model = keras.Model(inputs=model.input, outputs=model.get_layer('block3_conv3').output)\n",
        "modelshape = partial_model.output_shape # tensorflow shape\n",
        "print(modelshape)\n",
        "spatial_x = modelshape[1]\n",
        "spatial_y = modelshape[2]\n",
        "print(spatial_x,spatial_y)\n",
        "neuron = 5\n",
        "oris = [x for x in range(0,180,15)]\n",
        "periods = [x for x in range(5,35,5)]\n",
        "\n",
        "[maxori_ind, maxperiod_ind, theresponses] = tuningHeatmap(oris, periods, partial_model, spatial_x, spatial_y, neuron)\n",
        "maxori = oris[maxori_ind]\n",
        "maxperiod = periods[maxperiod_ind]\n",
        "print([maxori,maxperiod])"
      ],
      "metadata": {
        "id": "Hf64isq0dSnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heatmap and size tuning curve for a neuron"
      ],
      "metadata": {
        "id": "gFzLa7vJdV6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this paper, we created the tuning heatmap as above, and ran a range of in-silico experiments on artificial neural networks:\n",
        "# https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011486\n",
        "# The paper code: https://gin.g-node.org/xupan/CNN_surround_effects_visualization\n",
        "# Let's look at an example of increasing the diameter/size of a grating and testing the neural response\n",
        "# (this is known as a diameter or size tuning curve)\n",
        "\n",
        "# Here we go through some basic examples\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_size_tuning_curve(freq, orient, spatial_x, spatial_y, neuron, partial_model, maxgratingSize):\n",
        "   # Vary the grating sizes\n",
        "   sizes = list(range(1, maxgratingSize, 2))\n",
        "   responses = np.zeros(len(sizes))\n",
        "   for i, size in enumerate(sizes):\n",
        "        phase_responses = []\n",
        "        for phase in range(0, 316, 45):\n",
        "            sti = makeGrating(size=size, spatialp=freq, ori=orient, phase=phase, imsize=224)\n",
        "            if np.mod(i,5)==0 and phase==0:\n",
        "               plt.figure()\n",
        "               plt.draw();\n",
        "               plt.imshow(sti)\n",
        "               plt.pause(0.1)  # Pause for visualization\n",
        "            # Preprocess input\n",
        "            sti = np.expand_dims(sti, axis=0)\n",
        "            sti = preprocess_input(sti)\n",
        "            # run the model\n",
        "            prediction = partial_model.predict(sti, verbose=0)\n",
        "            # Get neuron response\n",
        "            response = prediction[0, spatial_x//2, spatial_y//2, neuron]\n",
        "            phase_responses.append(response)\n",
        "        # Compute the average response across the different phases\n",
        "        responses[i] = np.mean(phase_responses)\n",
        "   return sizes, responses"
      ],
      "metadata": {
        "id": "JsIlq4f7dfYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the size tuning curve for a neuron\n",
        "\n",
        "# Choose the neuron again from an intermediate layer\n",
        "partial_model = keras.Model(inputs=model.input, outputs=model.get_layer('block3_conv3').output)\n",
        "modelshape = partial_model.output_shape # tensorflow shape\n",
        "print(modelshape)\n",
        "spatial_x = modelshape[1]\n",
        "spatial_y = modelshape[2]\n",
        "print(spatial_x,spatial_y)\n",
        "neuron = 5\n",
        "print(neuron)\n",
        "\n",
        "# This is the heatmap function from before\n",
        "oris = [x for x in range(0,180,15)]\n",
        "periods = [x for x in range(5,35,5)]\n",
        "[maxori_ind, maxperiod_ind, theresponses] = tuningHeatmap(oris, periods, partial_model, spatial_x, spatial_y, neuron)\n",
        "maxori = oris[maxori_ind]\n",
        "maxperiod = periods[maxperiod_ind]\n",
        "print([maxori,maxperiod])\n",
        "\n",
        "# This is the size tuning\n",
        "maxgratingSize = 80\n",
        "sizes, responses = compute_size_tuning_curve(maxperiod, maxori, spatial_x, spatial_y, neuron, partial_model, maxgratingSize)\n",
        "plt.figure()\n",
        "plt.plot(sizes, responses, marker='o', linestyle='-')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Response\")\n",
        "plt.title(\"Size Tuning Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Vgu5pI2dluP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try another neuron\n",
        "\n",
        "# Choose the neuron again from an intermediate layer\n",
        "partial_model = keras.Model(inputs=model.input, outputs=model.get_layer('block3_conv3').output)\n",
        "modelshape = partial_model.output_shape # tensorflow shape\n",
        "print(modelshape)\n",
        "spatial_x = modelshape[1]\n",
        "spatial_y = modelshape[2]\n",
        "print(spatial_x,spatial_y)\n",
        "neuron = 2\n",
        "print(neuron)\n",
        "\n",
        "# This is the heatmap function from before\n",
        "oris = [x for x in range(0,180,15)]\n",
        "periods = [x for x in range(5,35,5)]\n",
        "[maxori_ind, maxperiod_ind, theresponses] = tuningHeatmap(oris, periods, partial_model, spatial_x, spatial_y, neuron)\n",
        "maxori = oris[maxori_ind]\n",
        "maxperiod = periods[maxperiod_ind]\n",
        "print([maxori,maxperiod])\n",
        "\n",
        "# This is the size tuning\n",
        "maxgratingSize = 80\n",
        "sizes, responses = compute_size_tuning_curve(maxperiod, maxori, spatial_x, spatial_y, neuron, partial_model, maxgratingSize)\n",
        "plt.figure()\n",
        "plt.plot(sizes, responses, marker='o', linestyle='-')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Response\")\n",
        "plt.title(\"Size Tuning Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FYTMO0gadpqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature visualization\n",
        "Now let's visualize a neuron's feature."
      ],
      "metadata": {
        "id": "fkb1LCpFd669"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "partial_model = keras.Model(inputs=model.input, outputs=model.get_layer('block3_conv3').output)\n",
        "neuron = 5\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "init_val = np.random.normal(size=(1,224,224,3), scale=0.01).astype(np.float32)\n",
        "im = tf.Variable(init_val)\n",
        "for epoch in range(100):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = -tf.reduce_mean(partial_model(im)[0,:,:,neuron]) # here we are using the whole spatial map of the neuron\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, loss = {loss.numpy():.5f}\")\n",
        "  gradients = tape.gradient(loss, [im])\n",
        "  opt.apply_gradients(zip(gradients, [im]))\n",
        "\n",
        "plt.imshow(im[0,...])"
      ],
      "metadata": {
        "id": "KVcvmFz2d97I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try visualizing another neuron.\n",
        "\n",
        "partial_model = keras.Model(inputs=model.input, outputs=model.get_layer('block4_conv2').output)\n",
        "neuron = 2\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "init_val = np.random.normal(size=(1,224,224,3), scale=0.01).astype(np.float32)\n",
        "im = tf.Variable(init_val)\n",
        "for epoch in range(100):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = -tf.reduce_mean(partial_model(im)[0,:,:,neuron])\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, loss = {loss.numpy():.5f}\")\n",
        "  gradients = tape.gradient(loss, [im])\n",
        "  opt.apply_gradients(zip(gradients, [im]))\n",
        "\n",
        "plt.imshow(im[0,...])"
      ],
      "metadata": {
        "id": "tqmQx9ZseAan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note on the visualization of features\n",
        "Above is only a minimal example of visualization. (An immediate but minor problem is we ignored the preprocess.) It often requires several tricks to obtain clear vivid features. An important trick is to use a natural image prior. This is usually done by putting a regulation loss on the Fourier spectrum (natural images are known to have spectrum slope of around 1.0).\n",
        "\n",
        "\n",
        "This distill article is a good learning resource: https://distill.pub/2017/feature-visualization/\n",
        "\n",
        "A newer study on more tricks: https://arxiv.org/pdf/2201.12961.pdf"
      ],
      "metadata": {
        "id": "Fl5mFBq6eEMa"
      }
    }
  ]
}